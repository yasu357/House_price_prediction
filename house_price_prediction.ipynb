{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\shaik\\.conda\\envs\\tensorflow\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"C:\\\\Users\\\\shaik\\\\Downloads\\\\archive (3)\\\\house_price_dataset\\\\data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  date      price  bedrooms  bathrooms  sqft_living  sqft_lot  \\\n",
      "0  2014-05-02 00:00:00   313000.0       3.0       1.50         1340      7912   \n",
      "1  2014-05-02 00:00:00  2384000.0       5.0       2.50         3650      9050   \n",
      "2  2014-05-02 00:00:00   342000.0       3.0       2.00         1930     11947   \n",
      "3  2014-05-02 00:00:00   420000.0       3.0       2.25         2000      8030   \n",
      "4  2014-05-02 00:00:00   550000.0       4.0       2.50         1940     10500   \n",
      "\n",
      "   floors  waterfront  view  condition  sqft_above  sqft_basement  yr_built  \\\n",
      "0     1.5           0     0          3        1340              0      1955   \n",
      "1     2.0           0     4          5        3370            280      1921   \n",
      "2     1.0           0     0          4        1930              0      1966   \n",
      "3     1.0           0     0          4        1000           1000      1963   \n",
      "4     1.0           0     0          4        1140            800      1976   \n",
      "\n",
      "   yr_renovated                    street       city  statezip country  \n",
      "0          2005      18810 Densmore Ave N  Shoreline  WA 98133     USA  \n",
      "1             0           709 W Blaine St    Seattle  WA 98119     USA  \n",
      "2             0  26206-26214 143rd Ave SE       Kent  WA 98042     USA  \n",
      "3             0           857 170th Pl NE   Bellevue  WA 98008     USA  \n",
      "4          1992         9105 170th Ave NE    Redmond  WA 98052     USA  \n"
     ]
    }
   ],
   "source": [
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Select the main 5 features\n",
    "features = ['sqft_living', 'sqft_lot', 'bedrooms', 'bathrooms', 'condition']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract features and target variable\n",
    "X = data[features]\n",
    "y = data['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\shaik\\.conda\\envs\\tensorflow\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Build a neural network using TensorFlow\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=len(features), activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\shaik\\.conda\\envs\\tensorflow\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:From c:\\Users\\shaik\\.conda\\envs\\tensorflow\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "115/115 [==============================] - 2s 3ms/step - loss: 438937485312.0000\n",
      "Epoch 2/50\n",
      "115/115 [==============================] - 0s 2ms/step - loss: 438858678272.0000\n",
      "Epoch 3/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 438553837568.0000\n",
      "Epoch 4/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 437833203712.0000\n",
      "Epoch 5/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 436556103680.0000\n",
      "Epoch 6/50\n",
      "115/115 [==============================] - 0s 2ms/step - loss: 434580684800.0000\n",
      "Epoch 7/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 431803957248.0000\n",
      "Epoch 8/50\n",
      "115/115 [==============================] - 0s 2ms/step - loss: 428135481344.0000\n",
      "Epoch 9/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 423555956736.0000\n",
      "Epoch 10/50\n",
      "115/115 [==============================] - 0s 2ms/step - loss: 417943814144.0000\n",
      "Epoch 11/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 411375304704.0000\n",
      "Epoch 12/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 403809075200.0000\n",
      "Epoch 13/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 395248500736.0000\n",
      "Epoch 14/50\n",
      "115/115 [==============================] - 0s 2ms/step - loss: 385694302208.0000\n",
      "Epoch 15/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 375233937408.0000\n",
      "Epoch 16/50\n",
      "115/115 [==============================] - 0s 2ms/step - loss: 363894308864.0000\n",
      "Epoch 17/50\n",
      "115/115 [==============================] - 0s 2ms/step - loss: 351814451200.0000\n",
      "Epoch 18/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 339055312896.0000\n",
      "Epoch 19/50\n",
      "115/115 [==============================] - 0s 2ms/step - loss: 325869305856.0000\n",
      "Epoch 20/50\n",
      "115/115 [==============================] - 0s 2ms/step - loss: 312337694720.0000\n",
      "Epoch 21/50\n",
      "115/115 [==============================] - 0s 2ms/step - loss: 298478370816.0000\n",
      "Epoch 22/50\n",
      "115/115 [==============================] - 0s 2ms/step - loss: 284430794752.0000\n",
      "Epoch 23/50\n",
      "115/115 [==============================] - 0s 2ms/step - loss: 270309687296.0000\n",
      "Epoch 24/50\n",
      "115/115 [==============================] - 0s 2ms/step - loss: 256334462976.0000\n",
      "Epoch 25/50\n",
      "115/115 [==============================] - 0s 2ms/step - loss: 242571706368.0000\n",
      "Epoch 26/50\n",
      "115/115 [==============================] - 0s 2ms/step - loss: 229175410688.0000\n",
      "Epoch 27/50\n",
      "115/115 [==============================] - 0s 2ms/step - loss: 216229117952.0000\n",
      "Epoch 28/50\n",
      "115/115 [==============================] - 0s 2ms/step - loss: 203834851328.0000\n",
      "Epoch 29/50\n",
      "115/115 [==============================] - 0s 2ms/step - loss: 192136003584.0000\n",
      "Epoch 30/50\n",
      "115/115 [==============================] - 0s 2ms/step - loss: 181142159360.0000\n",
      "Epoch 31/50\n",
      "115/115 [==============================] - 0s 2ms/step - loss: 171003822080.0000\n",
      "Epoch 32/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 161648410624.0000\n",
      "Epoch 33/50\n",
      "115/115 [==============================] - 0s 2ms/step - loss: 153122127872.0000\n",
      "Epoch 34/50\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 145506533376.0000\n",
      "Epoch 35/50\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 138743529472.0000\n",
      "Epoch 36/50\n",
      "115/115 [==============================] - 1s 4ms/step - loss: 132733607936.0000\n",
      "Epoch 37/50\n",
      "115/115 [==============================] - 1s 4ms/step - loss: 127454396416.0000\n",
      "Epoch 38/50\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 122825646080.0000\n",
      "Epoch 39/50\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 118826827776.0000\n",
      "Epoch 40/50\n",
      "115/115 [==============================] - 1s 6ms/step - loss: 115333201920.0000\n",
      "Epoch 41/50\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 112307347456.0000\n",
      "Epoch 42/50\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 109698883584.0000\n",
      "Epoch 43/50\n",
      "115/115 [==============================] - 0s 4ms/step - loss: 107409866752.0000\n",
      "Epoch 44/50\n",
      "115/115 [==============================] - 0s 2ms/step - loss: 105415114752.0000\n",
      "Epoch 45/50\n",
      "115/115 [==============================] - 0s 2ms/step - loss: 103662362624.0000\n",
      "Epoch 46/50\n",
      "115/115 [==============================] - 0s 2ms/step - loss: 102099140608.0000\n",
      "Epoch 47/50\n",
      "115/115 [==============================] - 0s 2ms/step - loss: 100700889088.0000\n",
      "Epoch 48/50\n",
      "115/115 [==============================] - 0s 2ms/step - loss: 99442180096.0000\n",
      "Epoch 49/50\n",
      "115/115 [==============================] - 0s 2ms/step - loss: 98303426560.0000\n",
      "Epoch 50/50\n",
      "115/115 [==============================] - 0s 2ms/step - loss: 97247051776.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2464b87d820>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 2ms/step - loss: 1017011634176.0000\n",
      "Mean Squared Error on Test Data: 1017011634176.0\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "mse = model.evaluate(X_test_scaled, y_test)\n",
    "print(f'Mean Squared Error on Test Data: {mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shaik\\.conda\\envs\\tensorflow\\lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "model.save('house_price_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['standard_scaler.pkl']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Save the scaler to a pickle file\n",
    "joblib.dump(scaler, 'standard_scaler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model and scaler\n",
    "model = load_model('house_price_model.h5')\n",
    "scaler = joblib.load('standard_scaler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppose you have new data for prediction\n",
    "new_data = pd.DataFrame({\n",
    "    'sqft_living': [1600],\n",
    "    'sqft_lot': [6000],\n",
    "    'bedrooms': [3],\n",
    "    'bathrooms': [2],\n",
    "    'condition': [3]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the new data using the same scaler\n",
    "new_data_scaled = scaler.transform(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 131ms/step\n"
     ]
    }
   ],
   "source": [
    "# Make predictions using the trained model\n",
    "new_predictions = model.predict(new_data_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Price: 249493.86\n"
     ]
    }
   ],
   "source": [
    "# Display the prediction\n",
    "print(f\"Predicted Price: {new_predictions[0][0]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
